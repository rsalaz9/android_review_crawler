{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from wordcloud import WordCloud\n",
    "# from spellchecker import SpellChecker\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataTest(path):\n",
    "    df = pd.read_csv(path, thousands = ',')\n",
    "#     df2 = df.drop(df.columns.difference(['Tweet_text']), axis=1)\n",
    "#     df2.columns = ['Anootated tweet']\n",
    "#     df2.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of start ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = loadDataTest(\"Facebook_review_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column in the df for rating category\n",
    "rating_category = []\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    if row['reviewer_ratings'] > 3:\n",
    "        rating_category.append(\"positive\")\n",
    "    if row['reviewer_ratings'] < 3:\n",
    "        rating_category.append(\"negative\")\n",
    "    if row['reviewer_ratings'] == 3:\n",
    "        rating_category.append(\"neutral\")\n",
    "reviews['rating_category'] = rating_category\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reviews['rating_category'])\n",
    "plt.ylabel(\"number of reviews\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.title(\"distribution of ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of main_info files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_native_apps = loadDataTest(\"Native_android_apps_reviews/main_info_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross_apps = loadDataTest(\"Xamarin_and_React_apps_reviews/main_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of ratings for each popularity category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_native_apps[\"number_of_downloads_category\"] = df_native_apps.apply (lambda row: label_popularity(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross_apps[\"number_of_downloads_category\"] = df_cross_apps.apply (lambda row: label_popularity(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_popularity (row):\n",
    "    if row['number_of_downloads'] == '10,000+' or row['number_of_downloads'] == '100,000+' :\n",
    "        return 1\n",
    "    if row['number_of_downloads'] == '500,000+' or row['number_of_downloads'] == '5,000,000+' or row['number_of_downloads'] == '1,000,000+':\n",
    "        return 2\n",
    "    if row['number_of_downloads'] == '10,000,000+' or row['number_of_downloads'] == '100,000,000+' or row['number_of_downloads'] == '50,000,000+':\n",
    "        return 3\n",
    "    if row['number_of_downloads'] == '5,000,000,000+' or row['number_of_downloads'] == '500,000,000+' or row['number_of_downloads'] == '1,000,000,000+':\n",
    "        return 4\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def avg_popularity(df):\n",
    "    num_apps_popularity = [0,0,0,0]\n",
    "    num_rating_popularity = [0,0,0,0]\n",
    "    avg_rating_popularity = [0,0,0,0]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['number_of_downloads_category'] == 1:\n",
    "            num_apps_popularity[0] += 1\n",
    "            num_rating_popularity[0] += row['number_of_ratings']\n",
    "        if row['number_of_downloads_category'] == 2:\n",
    "            num_apps_popularity[1] += 1\n",
    "            num_rating_popularity[1] += row['number_of_ratings']\n",
    "        if row['number_of_downloads_category'] == 3:\n",
    "            num_apps_popularity[2] += 1\n",
    "            num_rating_popularity[2] += row['number_of_ratings']\n",
    "        if row['number_of_downloads_category'] == 4:\n",
    "            num_apps_popularity[3] += 1\n",
    "            num_rating_popularity[3] += row['number_of_ratings']\n",
    "\n",
    "#     print(num_rating_popularity)\n",
    "#     print(num_apps_popularity)\n",
    "\n",
    "    return [x/y for x, y in zip(num_rating_popularity, num_apps_popularity)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_popularity(df_native_apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_popularity(df_cross_apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual cleaning, Stop word removal, punctuation removal, stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCleaning(df):\n",
    "    print(df)\n",
    "    df2 = df.copy()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.difference_update({'against','did', 'didn', \"didn't\",'don',\"don't\",'off','wasn',\"wasn't\",'won', \"won't\", 'wouldn', \"wouldn't\", })\n",
    "    ps = PorterStemmer()\n",
    "    WNLemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "#     if(train_test_flag == 'train'):\n",
    "#         df3 = pd.DataFrame(columns=['Anootated tweet', 'Class'])\n",
    "#     elif(train_test_flag == 'test'):\n",
    "    df3 = pd.DataFrame(columns=['review'])\n",
    "\n",
    "    for index, row in df2.iterrows():\n",
    "#         row['review'] = re.sub(r'(u.s|u.s.|U.S|US)',\"usa\", row['Anootated tweet'])\n",
    "        row['review'] = row['review'].lower()\n",
    "        row['review'] = re.sub(r'(<e>|<a>|</e>|</a>|<e/>|<a/>)', \" \", row['review'])\n",
    "#         row['review'] = re.sub(r'http\\S*', \" \", row['Anootated tweet'])\n",
    "        row['review'] = re.sub(r'[,\\/#!$%\\^&\\*;:{}=\\'\\-_`~()><:@\"“”?]',\"\", row['review'])\n",
    "        row['review'] = re.sub(r'(facebook|Facebook|fb|FB|app|use|see|time|friend|im|post|delete|Friend|want|know)',\" \", row['review'])\n",
    "#         row['review'] = re.sub(r'\\.',\" \", ['review'])\n",
    "        row['review'] = word_tokenize(row['review'])\n",
    "\n",
    "        correct = \"\"\n",
    "        for w in row['review']:\n",
    "#             print(w)\n",
    "            #pos tagging\n",
    "    \n",
    "            if (w in stop_words or len(w) == 1):\n",
    "                continue\n",
    "            tagged = nltk.pos_tag([w])\n",
    "            tag = tagged[0][1]\n",
    "\n",
    "            #lemmatize\n",
    "            if tag.startswith('J'):\n",
    "                tag = wn.ADJ\n",
    "            elif tag.startswith('V'):\n",
    "                tag = wn.VERB\n",
    "            elif tag.startswith('N'):\n",
    "                tag = wn.NOUN\n",
    "            elif tag.startswith('R'):\n",
    "                tag = wn.ADV\n",
    "            else:          \n",
    "                tag = wn.NOUN\n",
    "            word = WNLemmatizer.lemmatize(tagged[0][0], tag)\n",
    "\n",
    "            #stemming\n",
    "            word = ps.stem(word)\n",
    "\n",
    "            #stop word removal\n",
    "            correct += \" \" + word\n",
    "        \n",
    "     \n",
    "        \n",
    "        df3.loc[index] = [correct]\n",
    "        \n",
    "        \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = textCleaning(reviews1)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = \" \"\n",
    "for index, row in reviews.iterrows():\n",
    "    comment_words = comment_words+reviews.loc[index]['review'] + \" \"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "#                 stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words)\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "#                 stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words)\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
